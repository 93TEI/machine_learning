{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.8539592 [0.46933535] [-0.22949317]\n",
      "20 0.016810758 [0.9482225] [-0.01901533]\n",
      "40 0.00015370334 [0.99388045] [0.0008929]\n",
      "60 2.5571796e-06 [0.9982839] [0.00266149]\n",
      "80 1.0800496e-06 [0.9987566] [0.00270877]\n",
      "100 9.697441e-07 [0.9988522] [0.00259787]\n",
      "120 8.805942e-07 [0.9989097] [0.00247737]\n",
      "140 7.997501e-07 [0.9989612] [0.0023611]\n",
      "160 7.2638454e-07 [0.9990101] [0.00225019]\n",
      "180 6.5969334e-07 [0.9990566] [0.00214448]\n",
      "200 5.9919745e-07 [0.9991009] [0.00204374]\n",
      "220 5.442079e-07 [0.99914324] [0.0019477]\n",
      "240 4.943275e-07 [0.99918336] [0.0018562]\n",
      "260 4.4893395e-07 [0.99922174] [0.001769]\n",
      "280 4.0773867e-07 [0.9992583] [0.00168591]\n",
      "300 3.703723e-07 [0.9992932] [0.00160673]\n",
      "320 3.3635703e-07 [0.99932635] [0.00153124]\n",
      "340 3.0553664e-07 [0.99935794] [0.00145932]\n",
      "360 2.7752182e-07 [0.99938816] [0.00139078]\n",
      "380 2.520238e-07 [0.99941695] [0.00132545]\n",
      "400 2.2891719e-07 [0.9994443] [0.00126322]\n",
      "420 2.0791514e-07 [0.99947035] [0.00120389]\n",
      "440 1.8887789e-07 [0.99949527] [0.00114737]\n",
      "460 1.7152536e-07 [0.999519] [0.00109348]\n",
      "480 1.558161e-07 [0.9995416] [0.00104213]\n",
      "500 1.4154858e-07 [0.9995631] [0.00099319]\n",
      "520 1.2854913e-07 [0.99958354] [0.00094656]\n",
      "540 1.1673135e-07 [0.99960303] [0.00090211]\n",
      "560 1.06061954e-07 [0.9996217] [0.00085975]\n",
      "580 9.628892e-08 [0.9996396] [0.00081943]\n",
      "600 8.7468926e-08 [0.9996563] [0.00078099]\n",
      "620 7.945537e-08 [0.9996725] [0.00074433]\n",
      "640 7.218267e-08 [0.99968797] [0.00070942]\n",
      "660 6.558515e-08 [0.9997024] [0.00067615]\n",
      "680 5.957791e-08 [0.9997165] [0.00064443]\n",
      "700 5.413222e-08 [0.9997297] [0.00061422]\n",
      "720 4.917801e-08 [0.99974245] [0.00058537]\n",
      "740 4.465998e-08 [0.9997544] [0.00055795]\n",
      "760 4.057902e-08 [0.99976605] [0.00053174]\n",
      "780 3.684168e-08 [0.9997769] [0.00050684]\n",
      "800 3.3468837e-08 [0.99978757] [0.00048306]\n",
      "820 3.0412803e-08 [0.99979734] [0.00046039]\n",
      "840 2.762007e-08 [0.9998069] [0.00043886]\n",
      "860 2.5097284e-08 [0.999816] [0.00041823]\n",
      "880 2.282197e-08 [0.99982446] [0.00039864]\n",
      "900 2.0712553e-08 [0.9998328] [0.00038001]\n",
      "920 1.882736e-08 [0.9998406] [0.00036213]\n",
      "940 1.7089198e-08 [0.99984795] [0.0003452]\n",
      "960 1.5541564e-08 [0.9998551] [0.00032912]\n",
      "980 1.4113273e-08 [0.9998621] [0.00031366]\n",
      "1000 1.2825922e-08 [0.9998684] [0.00029893]\n",
      "1020 1.1670902e-08 [0.9998745] [0.00028499]\n",
      "1040 1.0578731e-08 [0.99988043] [0.0002717]\n",
      "1060 9.609366e-09 [0.99988616] [0.00025889]\n",
      "1080 8.730339e-09 [0.99989146] [0.00024673]\n",
      "1100 7.936895e-09 [0.99989635] [0.00023521]\n",
      "1120 7.2154385e-09 [0.9999011] [0.00022431]\n",
      "1140 6.5661587e-09 [0.9999059] [0.00021387]\n",
      "1160 5.9502554e-09 [0.9999104] [0.00020377]\n",
      "1180 5.4126494e-09 [0.9999146] [0.00019418]\n",
      "1200 4.921773e-09 [0.99991846] [0.00018511]\n",
      "1220 4.482388e-09 [0.99992216] [0.00017652]\n",
      "1240 4.07501e-09 [0.9999258] [0.00016835]\n",
      "1260 3.701378e-09 [0.99992937] [0.00016052]\n",
      "1280 3.3526295e-09 [0.9999328] [0.00015292]\n",
      "1300 3.0469447e-09 [0.999936] [0.00014566]\n",
      "1320 2.7691271e-09 [0.9999389] [0.0001388]\n",
      "1340 2.516406e-09 [0.9999417] [0.00013231]\n",
      "1360 2.2893876e-09 [0.9999444] [0.00012618]\n",
      "1380 2.076187e-09 [0.9999469] [0.00012037]\n",
      "1400 1.8916164e-09 [0.9999493] [0.00011486]\n",
      "1420 1.7217682e-09 [0.99995166] [0.0001096]\n",
      "1440 1.5665904e-09 [0.99995404] [0.0001045]\n",
      "1460 1.4213745e-09 [0.99995637] [9.951343e-05]\n",
      "1480 1.2885645e-09 [0.99995846] [9.4736315e-05]\n",
      "1500 1.1685538e-09 [0.9999604] [9.021829e-05]\n",
      "1520 1.0631425e-09 [0.9999622] [8.594264e-05]\n",
      "1540 9.632544e-10 [0.99996394] [8.190463e-05]\n",
      "1560 8.7573443e-10 [0.9999656] [7.8085955e-05]\n",
      "1580 7.9619156e-10 [0.99996716] [7.4476295e-05]\n",
      "1600 7.2310985e-10 [0.99996865] [7.105897e-05]\n",
      "1620 6.6052525e-10 [0.99997] [6.782761e-05]\n",
      "1640 6.031892e-10 [0.99997133] [6.4767904e-05]\n",
      "1660 5.51708e-10 [0.9999726] [6.186715e-05]\n",
      "1680 5.0310217e-10 [0.9999738] [5.9129306e-05]\n",
      "1700 4.5923798e-10 [0.99997497] [5.6507502e-05]\n",
      "1720 4.1977444e-10 [0.99997616] [5.396675e-05]\n",
      "1740 3.8043405e-10 [0.99997735] [5.147686e-05]\n",
      "1760 3.431874e-10 [0.99997854] [4.9013997e-05]\n",
      "1780 3.1141192e-10 [0.99997973] [4.6594854e-05]\n",
      "1800 2.806786e-10 [0.9999806] [4.427027e-05]\n",
      "1820 2.528632e-10 [0.99998164] [4.208238e-05]\n",
      "1840 2.287995e-10 [0.99998254] [4.001291e-05]\n",
      "1860 2.0655004e-10 [0.9999834] [3.8049926e-05]\n",
      "1880 1.890091e-10 [0.99998415] [3.6195026e-05]\n",
      "1900 1.6988604e-10 [0.99998486] [3.4439476e-05]\n",
      "1920 1.5450041e-10 [0.99998564] [3.2781663e-05]\n",
      "1940 1.3906269e-10 [0.9999863] [3.121129e-05]\n",
      "1960 1.2592712e-10 [0.99998695] [2.9728322e-05]\n",
      "1980 1.1486634e-10 [0.99998754] [2.8328004e-05]\n",
      "2000 1.0554402e-10 [0.9999881] [2.7003987e-05]\n"
     ]
    }
   ],
   "source": [
    "# cost function\n",
    "# 션형그래프가 가설과 얼마나 차이나는지 계산\n",
    "# 가장 작은 것을 구해야 하기 때문에 min(cosr(W,b)) // H(x) = Wx + b\n",
    "# 제곱을 하면 차이가 양수로 나올 뿐 아니라 가중치 처리 가능\n",
    "import tensorflow as tf\n",
    "\n",
    "X_train = [1,2,3]\n",
    "Y_train = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight') # 첫 매개변수는 몇차원인지 알려주는것\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# H(x) = Wx + b\n",
    "hypothesis = X_train * W + b\n",
    "\n",
    "#cost function 계산식 적용\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y_train)) #reduce_mean : 평균내주는거\n",
    "\n",
    "# GradientDescent\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost) # variable을 조정해서 가장 작은거 찾음\n",
    "\n",
    "# 그래프를 세션에서 실행\n",
    "sess = tf.compat.v1.Session()\n",
    "# W,b 라는 변수를 사용했는데, 이걸 사용할 땐 tf.global_variables_initializer를 해야함\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001) :\n",
    "    # train이라는 노드를 실행함으로써 그래프 상 연결되어있는 노드가 모두 순차적 실행됨\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0 : # 과정을 눈으로 보기 위함\n",
    "        print(step, sess.run(cost), sess.run(W),sess.run(b))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.957084 [0.01519825] [-0.7184573]\n",
      "20 0.09768114 [0.9964097] [-0.27341548]\n",
      "40 0.007609226 [1.0856018] [-0.2214044]\n",
      "60 0.0061754696 [1.0900556] [-0.20727035]\n",
      "80 0.0056019984 [1.0866305] [-0.19717441]\n",
      "100 0.005087757 [1.082636] [-0.18787415]\n",
      "120 0.004620781 [1.0787597] [-0.1790415]\n",
      "140 0.004196665 [1.075059] [-0.17062688]\n",
      "160 0.003811482 [1.0715315] [-0.16260803]\n",
      "180 0.0034616461 [1.0681698] [-0.154966]\n",
      "200 0.0031439217 [1.0649661] [-0.14768316]\n",
      "220 0.0028553547 [1.0619129] [-0.14074257]\n",
      "240 0.0025932717 [1.0590031] [-0.13412806]\n",
      "260 0.0023552554 [1.0562302] [-0.12782452]\n",
      "280 0.0021390833 [1.0535877] [-0.12181723]\n",
      "300 0.0019427558 [1.0510694] [-0.11609233]\n",
      "320 0.0017644367 [1.0486691] [-0.11063645]\n",
      "340 0.0016024952 [1.0463818] [-0.10543695]\n",
      "360 0.0014554072 [1.0442021] [-0.1004818]\n",
      "380 0.0013218244 [1.0421247] [-0.09575954]\n",
      "400 0.0012005056 [1.0401452] [-0.09125933]\n",
      "420 0.0010903181 [1.0382584] [-0.08697039]\n",
      "440 0.0009902436 [1.0364603] [-0.08288305]\n",
      "460 0.00089935336 [1.0347469] [-0.07898781]\n",
      "480 0.00081680744 [1.033114] [-0.07527567]\n",
      "500 0.00074183516 [1.0315577] [-0.071738]\n",
      "520 0.00067375397 [1.0300747] [-0.06836665]\n",
      "540 0.00061190926 [1.0286613] [-0.0651537]\n",
      "560 0.00055575 [1.0273143] [-0.06209173]\n",
      "580 0.0005047396 [1.0260307] [-0.05917368]\n",
      "600 0.00045841467 [1.0248073] [-0.05639278]\n",
      "620 0.000416339 [1.0236415] [-0.05374254]\n",
      "640 0.00037812453 [1.0225304] [-0.05121684]\n",
      "660 0.0003434214 [1.0214717] [-0.04880991]\n",
      "680 0.00031190025 [1.0204623] [-0.04651602]\n",
      "700 0.00028326988 [1.0195005] [-0.04432974]\n",
      "720 0.00025726712 [1.0185841] [-0.0422463]\n",
      "740 0.00023365486 [1.0177108] [-0.04026084]\n",
      "760 0.0002122082 [1.0168784] [-0.03836872]\n",
      "780 0.0001927325 [1.0160851] [-0.03656548]\n",
      "800 0.00017504283 [1.0153292] [-0.03484702]\n",
      "820 0.00015897413 [1.0146089] [-0.03320933]\n",
      "840 0.00014438378 [1.0139223] [-0.03164861]\n",
      "860 0.00013113306 [1.013268] [-0.0301613]\n",
      "880 0.00011909657 [1.0126444] [-0.0287438]\n",
      "900 0.000108165455 [1.0120502] [-0.02739294]\n",
      "920 9.823655e-05 [1.0114839] [-0.02610558]\n",
      "940 8.922167e-05 [1.0109442] [-0.02487873]\n",
      "960 8.1031976e-05 [1.01043] [-0.02370954]\n",
      "980 7.359566e-05 [1.0099398] [-0.0225954]\n",
      "1000 6.684003e-05 [1.0094726] [-0.02153346]\n",
      "1020 6.070457e-05 [1.0090275] [-0.02052145]\n",
      "1040 5.5132932e-05 [1.0086032] [-0.01955704]\n",
      "1060 5.007324e-05 [1.0081989] [-0.01863792]\n",
      "1080 4.5476685e-05 [1.0078136] [-0.017762]\n",
      "1100 4.1302977e-05 [1.0074463] [-0.01692727]\n",
      "1120 3.7512586e-05 [1.0070964] [-0.01613174]\n",
      "1140 3.407016e-05 [1.006763] [-0.01537367]\n",
      "1160 3.0941894e-05 [1.006445] [-0.0146512]\n",
      "1180 2.8102746e-05 [1.0061423] [-0.01396265]\n",
      "1200 2.5523608e-05 [1.0058535] [-0.01330648]\n",
      "1220 2.3180457e-05 [1.0055784] [-0.01268112]\n",
      "1240 2.10531e-05 [1.0053164] [-0.01208517]\n",
      "1260 1.912067e-05 [1.0050665] [-0.01151724]\n",
      "1280 1.7366128e-05 [1.0048283] [-0.01097602]\n",
      "1300 1.5772412e-05 [1.0046015] [-0.01046021]\n",
      "1320 1.43244515e-05 [1.0043852] [-0.00996863]\n",
      "1340 1.3009808e-05 [1.0041792] [-0.00950018]\n",
      "1360 1.1815624e-05 [1.0039828] [-0.00905376]\n",
      "1380 1.07316155e-05 [1.0037956] [-0.00862829]\n",
      "1400 9.746753e-06 [1.0036173] [-0.0082228]\n",
      "1420 8.851857e-06 [1.0034472] [-0.00783637]\n",
      "1440 8.039736e-06 [1.0032853] [-0.00746809]\n",
      "1460 7.301725e-06 [1.0031309] [-0.00711716]\n",
      "1480 6.631703e-06 [1.0029838] [-0.00678271]\n",
      "1500 6.0229468e-06 [1.0028436] [-0.00646401]\n",
      "1520 5.47043e-06 [1.00271] [-0.00616029]\n",
      "1540 4.9685564e-06 [1.0025827] [-0.00587081]\n",
      "1560 4.512424e-06 [1.0024613] [-0.00559497]\n",
      "1580 4.0980367e-06 [1.0023456] [-0.00533204]\n",
      "1600 3.7222162e-06 [1.0022354] [-0.00508149]\n",
      "1620 3.3804965e-06 [1.0021304] [-0.00484269]\n",
      "1640 3.0705025e-06 [1.0020304] [-0.00461514]\n",
      "1660 2.7886006e-06 [1.001935] [-0.00439832]\n",
      "1680 2.5326358e-06 [1.001844] [-0.0041917]\n",
      "1700 2.3004077e-06 [1.0017573] [-0.00399479]\n",
      "1720 2.089316e-06 [1.0016749] [-0.00380711]\n",
      "1740 1.8975965e-06 [1.0015962] [-0.00362825]\n",
      "1760 1.7236298e-06 [1.0015212] [-0.00345784]\n",
      "1780 1.5653991e-06 [1.0014498] [-0.0032954]\n",
      "1800 1.4217215e-06 [1.0013818] [-0.00314064]\n",
      "1820 1.2914458e-06 [1.0013167] [-0.00299311]\n",
      "1840 1.1729031e-06 [1.0012549] [-0.00285251]\n",
      "1860 1.0653871e-06 [1.001196] [-0.00271853]\n",
      "1880 9.677059e-07 [1.0011399] [-0.00259084]\n",
      "1900 8.788465e-07 [1.0010864] [-0.00246916]\n",
      "1920 7.982647e-07 [1.0010355] [-0.00235323]\n",
      "1940 7.2517605e-07 [1.0009868] [-0.00224276]\n",
      "1960 6.586779e-07 [1.0009406] [-0.00213748]\n",
      "1980 5.982752e-07 [1.0008965] [-0.00203716]\n",
      "2000 5.4335356e-07 [1.0008543] [-0.00194154]\n"
     ]
    }
   ],
   "source": [
    "# 코드 복습\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=None)\n",
    "y = tf.placeholder(tf.float32, shape=None)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "hypothesis = W * x + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "optimazer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimazer.minimize(cost)\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001) :\n",
    "    c_v,W_v,b_v,_=sess.run([cost,W,b,train],feed_dict = {x:[1,2,3],y:[1,2,3]})\n",
    "    if step % 20 == 0 :\n",
    "        print(step, c_v, W_v, b_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
